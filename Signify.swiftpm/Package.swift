// swift-tools-version: 6.0

// WARNING:
// This file is automatically generated.
// Do not edit it by hand because the contents will be replaced.

import PackageDescription
import AppleProductTypes

let package = Package(
    name: "Signify",
    platforms: [
        .iOS("16.0")
    ],
    products: [
        .iOSApplication(
            name: "Signify",
            targets: ["AppModule"],
            bundleIdentifier: "com.Signify.SSC",
            teamIdentifier: "B6QMD2854G",
            displayVersion: "1.0",
            bundleVersion: "1",
            appIcon: .placeholder(icon: .weights),
            accentColor: .presetColor(.green),
            supportedDeviceFamilies: [
                .pad,
                .phone
            ],
            supportedInterfaceOrientations: [
                .landscapeRight,
                .portraitUpsideDown(.when(deviceFamilies: [.pad]))
            ],
            capabilities: [
                .camera(purposeString: "Signify requires access to your camera and microphone to provide real-time subtitles. Please grant permission to continue."),
                .microphone(purposeString: "To use Signify, please allow access to your camera for sign language recognition and your microphone for speech transcription."),
                .speechRecognition(purposeString: "To use Signify, please allow access to your camera for sign language recognition and your microphone for speech transcription.")
            ]
        )
    ],
    targets: [
        .executableTarget(
            name: "AppModule",
            path: ".",
            resources: [
                .copy("MLModel")
            ]
        )
    ]
)